model_list:
  # Anthropic Claude Models - Latest (December 2025)
  # All models have cache_control_injection_points to enable automatic prompt caching
  # This adds cache_control: {type: "ephemeral"} to system messages for 90% cost savings
  - model_name: claude-opus-4-5
    litellm_params:
      model: anthropic/claude-opus-4-5-20251101
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 8192
      cache_control_injection_points:
        - location: message
          role: system

  - model_name: claude-sonnet-4-5
    litellm_params:
      model: anthropic/claude-sonnet-4-5-20250929
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 8192
      cache_control_injection_points:
        - location: message
          role: system

  # Claude Sonnet 4 (previous generation)
  - model_name: claude-sonnet-4
    litellm_params:
      model: anthropic/claude-sonnet-4-20250514
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 8192
      cache_control_injection_points:
        - location: message
          role: system

  # Claude 3.7 Sonnet (replaces 3.5 Sonnet)
  - model_name: claude-3-7-sonnet
    litellm_params:
      model: anthropic/claude-3-7-sonnet-20250219
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 8192
      cache_control_injection_points:
        - location: message
          role: system

  - model_name: claude-3-5-haiku
    litellm_params:
      model: anthropic/claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 8192
      cache_control_injection_points:
        - location: message
          role: system

  # Claude Haiku 4.5 (Fast & cost-effective)
  - model_name: claude-haiku-4-5
    litellm_params:
      model: anthropic/claude-haiku-4-5-20251001
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 8192
      cache_control_injection_points:
        - location: message
          role: system

  # OpenAI Models - Latest (December 2025)

  # GPT-5.2 Series (Latest flagship - 400K context)
  - model_name: gpt-5.2
    litellm_params:
      model: openai/gpt-5.2
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 128000

  - model_name: gpt-5.2-pro
    litellm_params:
      model: openai/gpt-5.2-pro
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 128000

  - model_name: gpt-5.2-chat-latest
    litellm_params:
      model: openai/gpt-5.2-chat-latest
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 128000

  # GPT-5.1 Series (Flagship for coding & agentic tasks)
  - model_name: gpt-5.1
    litellm_params:
      model: openai/gpt-5.1
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 128000

  - model_name: gpt-5.1-chat-latest
    litellm_params:
      model: openai/gpt-5.1-chat-latest
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 128000

  # GPT-5.1 Codex Models (Specialized for agentic coding)
  - model_name: gpt-5.1-codex-max
    litellm_params:
      model: openai/gpt-5.1-codex-max
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 128000

  - model_name: gpt-5.1-codex-mini
    litellm_params:
      model: openai/gpt-5.1-codex-mini
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 64000

  # GPT-4o Series (Multimodal - text, images, audio)
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 16384

  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 16384

  # GPT-4.1 Series (1M context window)
  - model_name: gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 32768

  - model_name: gpt-4.1-mini
    litellm_params:
      model: openai/gpt-4.1-mini
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 32768

  # O-Series Reasoning Models
  - model_name: o3
    litellm_params:
      model: openai/o3
      api_key: os.environ/OPENAI_API_KEY

  - model_name: o3-mini
    litellm_params:
      model: openai/o3-mini
      api_key: os.environ/OPENAI_API_KEY

  - model_name: o4-mini
    litellm_params:
      model: openai/o4-mini
      api_key: os.environ/OPENAI_API_KEY

litellm_settings:
  drop_params: true
  set_verbose: false
  cache: false
  
router_settings:
  model_group_alias:
    claude: ["claude-opus-4-5", "claude-sonnet-4-5", "claude-sonnet-4", "claude-3-7-sonnet", "claude-haiku-4-5", "claude-3-5-haiku"]
    gpt: ["gpt-5.2", "gpt-5.2-pro", "gpt-5.1", "gpt-4o", "gpt-4o-mini", "gpt-4.1", "gpt-4.1-mini"]
    codex: ["gpt-5.1-codex-max", "gpt-5.1-codex-mini"]
    reasoning: ["o3", "o3-mini", "o4-mini"]

  fallback_models:
    claude-opus-4-5: ["claude-sonnet-4-5", "claude-sonnet-4"]
    claude-sonnet-4-5: ["claude-sonnet-4", "claude-3-7-sonnet"]
    claude-sonnet-4: ["claude-3-7-sonnet", "claude-3-5-haiku"]
    claude-3-7-sonnet: ["claude-sonnet-4", "claude-haiku-4-5", "claude-3-5-haiku"]
    claude-haiku-4-5: ["claude-3-5-haiku", "claude-3-7-sonnet"]
    gpt-5.2: ["gpt-5.2-pro", "gpt-5.1", "gpt-4o"]
    gpt-5.2-pro: ["gpt-5.2", "gpt-5.1", "gpt-4o"]
    gpt-5.1: ["gpt-5.2", "gpt-4o", "gpt-4.1"]
    gpt-5.1-codex-max: ["gpt-5.1-codex-mini", "gpt-5.1"]
    gpt-4o: ["gpt-4o-mini", "gpt-4.1", "gpt-5.1"]
    gpt-4.1: ["gpt-4.1-mini", "gpt-4o"]
    o3: ["o3-mini", "o4-mini"]
    o3-mini: ["o4-mini"]

general_settings:
  # Logging
  log_level: INFO

  # Timeout settings
  request_timeout: 600
  stream_timeout: 60
